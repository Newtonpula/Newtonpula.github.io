

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/title.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="A brief introduction to Takens&#39;s theorem. Applications are included.">
<meta property="og:type" content="article">
<meta property="og:title" content="Takens&#39;s Theorem">
<meta property="og:url" content="http://example.com/2023/10/04/Takens-s-Theorem/index.html">
<meta property="og:site_name" content="Newtonpula&#39;s Land">
<meta property="og:description" content="A brief introduction to Takens&#39;s theorem. Applications are included.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/index/takens.jpg">
<meta property="article:published_time" content="2023-10-04T10:49:19.000Z">
<meta property="article:modified_time" content="2024-11-19T14:08:59.902Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="math">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/index/takens.jpg">
  
  
  
  <title>Takens&#39;s Theorem - Newtonpula&#39;s Land</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Newtonpula&#39;s Land</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg/head.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Takens&#39;s Theorem"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-10-04 18:49" pubdate>
          October 4, 2023 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          75 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Takens&#39;s Theorem</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="takenss-theorem">Takens's Theorem</h1>
<p>Takens's theorem shows connection between space and time, which is an
important result in dynamical system. It also relates to ergodic theory
and have applications in many fields. The proof is much obscure since
it's mainly based on ideas from differential topology. The original
proof is by, of course,
Takens<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="F. Takens, “Detecting strange attractors in turbulence,” in Dynamical Systems and Turbulence, Warwick 1980, vol. 898, D. Rand and L.-S. Young, Eds., in Lecture Notes in Mathematics, vol. 898. , Berlin, Heidelberg: Springer Berlin Heidelberg, 1981, pp. 366–381. doi: 10.1007/BFb0091924.">[8]</span></a></sup>.
Sauer, Yorke and
Casdgali<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="T. Sauer, J. A. Yorke, and M. Casdagli, “Embedology,” J Stat Phys, vol. 65, no. 3–4, pp. 579–616, Nov. 1991, doi: 10.1007/BF01053745.">[6]</span></a></sup>
generalized Takens's work. One big point is that manifolds are
generalized to subset of <span
class="math inline">\(\mathbb{R}^{k}\)</span> with certain box-counting
dimension. Here we do not give the proof of Takens's theorem. Both
original and explanatory materials
exist<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="J. P. Huke, “Embedding Nonlinear Dynamical Systems: A Guide to Takens’ Theorem.” Mar. 2006. [Online]. Available: https://api.semanticscholar.org/CorpusID:55183186">[2]</span></a></sup>
<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="J. Penalva Vadell, “Takens’s theorem proof and applications.pdf.” 2018.">[5]</span></a></sup>
<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="T. Sauer, J. A. Yorke, and M. Casdagli, “Embedology,” J Stat Phys, vol. 65, no. 3–4, pp. 579–616, Nov. 1991, doi: 10.1007/BF01053745.">[6]</span></a></sup>
<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="F. Takens, “Detecting strange attractors in turbulence,” in Dynamical Systems and Turbulence, Warwick 1980, vol. 898, D. Rand and L.-S. Young, Eds., in Lecture Notes in Mathematics, vol. 898. , Berlin, Heidelberg: Springer Berlin Heidelberg, 1981, pp. 366–381. doi: 10.1007/BFb0091924.">[8]</span></a></sup>.
We focus on applications of Takens's theorem, including reconstruction
of attractor from time series
data<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="H. Ma, S. Leng, K. Aihara, W. Lin, and L. Chen, “Randomly distributed embedding making short-term high-dimensional data predictable,” Proc. Natl. Acad. Sci. U.S.A., vol. 115, no. 43, Oct. 2018, doi: 10.1073/pnas.1802987115.">[4]</span></a></sup>
and change-point
detection<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="J.-W. Hou, H.-F. Ma, D. He, J. Sun, Q. Nie, and W. Lin, “Harvesting random embedding for high-frequency change-point detection in temporal complex systems,” National Science Review, vol. 9, no. 4, p. nwab228, May 2022, doi: 10.1093/nsr/nwab228.">[1]</span></a></sup>.</p>
<h2 id="box-counting-dimension">box-counting dimension</h2>
<p>The Minkowski-Bouigand dimension, also known as Minkowski dimension
or box-counting dimension.</p>
<p>Denote <span class="math inline">\(N(\varepsilon)\)</span> is the
number of boxes of side length <span
class="math inline">\(\varepsilon\)</span> required to cover the set.
Then the box-counting dimension is defined as <span
class="math display">\[
    \dim_{\text{box}}(S):=\lim_{\varepsilon\to 0}\frac{\log
N(\varepsilon)}{\log 1 / \varepsilon}
\]</span></p>
<p>If <span class="math inline">\(S\)</span> is a smooth space (a
manifold) of integer dimension <span class="math inline">\(d\)</span>,
then <span class="math inline">\(N(1 / n) \thickapprox Cn^{d}\)</span>,
which corresponds with the normal definition of dimension.</p>
<p>When the above limit does not exist, upper and lower box-counting
dimensions can be defined, and they are strongly related to the
Hausdorff dimension.</p>
<h2 id="some-definitions">some definitions</h2>
<p>First we need to clarify what is an attractor.</p>
<p><strong>Def 1</strong> Let <span
class="math inline">\(\phi(t,x)\)</span> is a flow. A <strong>positively
invariant set</strong> <span class="math inline">\(A\)</span> from a
flow <span class="math inline">\(\phi(t,x)\)</span> is a set such that
if <span class="math inline">\(\phi(t_0,x) \in A\)</span> for some <span
class="math inline">\(t_0\)</span>, then <span
class="math inline">\(\phi(t,x)\in A\)</span> for all <span
class="math inline">\(t\geqslant t_0\)</span>.</p>
<p><strong>Def 2</strong> A <strong>stable set</strong> from a
continuous dynamical system of flow <span
class="math inline">\(\phi(t,x)\)</span> is a set such that there exists
a neighborhood <span class="math inline">\(B\)</span> of <span
class="math inline">\(S\)</span> satisfying that if <span
class="math inline">\(\phi(t_0,x)\in B\)</span>, then <span
class="math inline">\(\phi(t,x)\in B\)</span> for all <span
class="math inline">\(t\geqslant t_0\)</span>.</p>
<p>Futhermore, if there exists a neighborhood <span
class="math inline">\(B\)</span> such that, for every neighborhood <span
class="math inline">\(B&#39; \subset B\)</span>, if <span
class="math inline">\(\phi(t_0,x) \in B\)</span>, then there exists
<span class="math inline">\(t_1\geqslant t_0\)</span> such that <span
class="math inline">\(\phi(t_0,x)\in B&#39;\)</span> for every <span
class="math inline">\(t\geqslant t_1\)</span>, then <span
class="math inline">\(S\)</span> is also an <strong>asymptotically
stable set</strong>.</p>
<p><strong>Def 3</strong> An <strong>attracting set</strong> of an ODE
is a closed, positively invariant and asymptotically stable set. An
attractor of an ODE is an attracting set which contains a dense
orbit.</p>
<p><strong>Def 4</strong> let <span class="math inline">\(M\)</span> be
a manifold. The set of <span class="math inline">\(C^{r}\)</span>
functions from <span class="math inline">\(M\)</span> to itself which
are also diffeomorphisms (have <span
class="math inline">\(C^{r}\)</span> inverse) is called <span
class="math inline">\(Diff^{r}(M)\)</span>.</p>
<h2 id="takens-embedding-theorem">Takens' embedding theorem</h2>
<p><strong>Theorem 1</strong> Let <span class="math inline">\(M\)</span>
be a compact manifold of dimension <span
class="math inline">\(m\)</span>. For pairs <span
class="math inline">\((\phi, y)\)</span>, with <span
class="math inline">\(\phi \in Diff^{2}(M)\)</span>, <span
class="math inline">\(y \in C^{2}(M, \mathbb{R})\)</span>, it is a
generic property that the map <span class="math inline">\(\Phi_{(\phi,
y)}\colon M \rightarrow \mathbb{R}^{2m+1}\)</span>, defined by <span
class="math display">\[
    \Phi_{(\phi, y)}(x) = (y(x), y(\phi(x)), \cdots , y(\phi^{2m}(x)))
\]</span></p>
<p>is an embedding. Recall Whitney embedding theorem. This mean that
<span class="math inline">\(\Phi_{(\phi,y)}(M)\)</span> is diffeomorphic
to <span class="math inline">\(M\)</span> (in the sense of <span
class="math inline">\(C^{2}\)</span>)</p>
<p>Here 'generic' means open and dense, and we use the <span
class="math inline">\(C^{1}\)</span> topology. We refer to the functions
<span class="math inline">\(y\in C^{2}(M,\mathbb{R})\)</span> as
<strong>measurement functions</strong>.</p>
<p>Another version focusing on one particular <span
class="math inline">\(\phi\)</span> is that:</p>
<p><strong>Theorem 2</strong> Let <span class="math inline">\(M\)</span>
be as above. Let <span class="math inline">\(\phi \colon M\rightarrow
M\)</span> be a diffeomorphism, with the properties: - the periodic
points of <span class="math inline">\(\phi\)</span> with periods less
than or equal to <span class="math inline">\(2m\)</span> are finite in
number; - if <span class="math inline">\(x\)</span> is any periodic
point with period <span class="math inline">\(k\leqslant 2m\)</span>
then the eigenvalues of the derivative of <span
class="math inline">\(\phi^{k}\)</span> at <span
class="math inline">\(x\)</span> are all distinct.</p>
<p>Then for generic <span class="math inline">\(y \in C^{2}(M,
\mathbb{R})\)</span>, the map <span
class="math inline">\(\Phi_{(\phi,y)}\colon M \rightarrow
\mathbb{R}^{2m+1}\)</span>, defined as in Theorem 1, is an
embedding.</p>
<p><strong>Remark</strong> When theorem 1 gives stronger results,
theorem 2 gives a sufficient condition for the diffeomorphism <span
class="math inline">\(\phi\)</span>, this may be informative in
applications. Though the expression and proof of Takens's theorem is all
about existence, we usually have alternatives for <span
class="math inline">\(\phi\)</span> and <span
class="math inline">\(y\)</span> in many set ups: if <span
class="math inline">\(M\)</span> is the strange attractor of a dynamical
system, then <span class="math inline">\(\phi\)</span> is usually the
flow with a certain time delay, and <span
class="math inline">\(y\)</span> is the observable or measurement.
<strong>However</strong>, we do not know if such <span
class="math inline">\(\phi\)</span> and <span
class="math inline">\(y\)</span> are appropriate.</p>
<h2 id="applications-of-takenss-theorem">Applications of Takens's
theorem</h2>
<p>I saw two papers
<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="H. Ma, S. Leng, K. Aihara, W. Lin, and L. Chen, “Randomly distributed embedding making short-term high-dimensional data predictable,” Proc. Natl. Acad. Sci. U.S.A., vol. 115, no. 43, Oct. 2018, doi: 10.1073/pnas.1802987115.">[4]</span></a></sup>
<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="J.-W. Hou, H.-F. Ma, D. He, J. Sun, Q. Nie, and W. Lin, “Harvesting random embedding for high-frequency change-point detection in temporal complex systems,” National Science Review, vol. 9, no. 4, p. nwab228, May 2022, doi: 10.1093/nsr/nwab228.">[1]</span></a></sup>
before I determined to write this post. A framework, randomly
distributed embedding (RDE) was proposed to reconstruct state space and
predict future states. Later, the same group developed another
framework, temporal change-point detection (TCD), to detect
change-points, where RDE served as the very first step. They are not
direct application of Takens's theorem, but they are based on the idea
of embedding theorem.</p>
<h3 id="reconstruction-of-state-space-and-prediction">Reconstruction of
state space and prediction</h3>
<p>The first idea roots in the theory of generalized embedding, where
one can reconstruct the original system by both delayed embedding and
non-delayed embedding.</p>
<p>Suppose we have a time series <span
class="math inline">\(\{\bm{x}(t)\}\in \mathbb{R}^{n\times
\mathbb{R}}\)</span>. <span class="math inline">\(x_s(t)\)</span> is one
of the interested observables of <span
class="math inline">\(\bm{x}\)</span>. Then - A delayed embedding: <span
class="math inline">\(\mathcal{N}=\{x_s(t),x_s(t+\tau),\cdots
,x_s(t+(E-1)\tau)\}\)</span>. - A non-delayed embedding: <span
class="math inline">\(\mathcal{M}=\{x_{k_1}(t),x_{k_2}(t),\cdots
,x_{k_E}(t)\}\)</span>.</p>
<p>Here, theoretically, the embedding dimension <span
class="math inline">\(E&gt;2d\)</span> is required and <span
class="math inline">\(d\)</span> is the box-counting dimension of the
system dynamics. The determination of <span
class="math inline">\(E\)</span> in practice, however, is not easy.</p>
<p>In priciple, there exists a diffeomorphism <span
class="math inline">\(\bm{\Psi}\colon \mathcal{M}\rightarrow
\mathcal{N}\)</span>. Specifically, <span class="math display">\[
    x_s(t+\tau)=\psi(x_{k_1}(t),x_{k_2}(t),\cdots ,x_{k_E}(t))
\]</span></p>
<p>How to reconstruct the state space and do one-step prediction? The
process consists of several steps:</p>
<ol type="1">
<li>Randomly select a tuple <span
class="math inline">\(\bm{k}=(k_1,\cdots ,k_{E})\)</span></li>
<li>fit a predictor <span class="math inline">\(\psi{\bm{k}}\)</span> by
minimizing <span class="math inline">\(\left\|
x_s(t+\tau)-\psi(x_{k_1}(t),x_{k_2}(t),\cdots ,x_{k_E}(t)) \right\|_{},
t=t_1,\cdots,t_q\)</span>. The authors used Gaussian Process Regression
(GPR) to fit the predictor.</li>
<li>Make a one-step prediction as <span
class="math inline">\(\hat{x}_s^{\bm{k}}(T+\tau)=\psi_{\bm{k}}(x_{k_1}(T),x_{k_2}(T),\cdots
,x_{k_E}(T))\)</span>.</li>
<li>Repeat steps 1-3 by randomly picking up another <span
class="math inline">\(r\)</span> tuples. Now we have <span
class="math inline">\(r\)</span> predictions <span
class="math inline">\(\{\hat{x}_s^{\bm{k}}(T+\tau)\}\)</span>.</li>
<li>Statistical analysis of <span
class="math inline">\(\{\hat{x}_s^{\bm{k}}(T+\tau)\}\)</span>. Exclude
the outliers by calculating the quartiles of the predictions.</li>
<li>Using kernel density estimation to estimate the probability density
function of the predictions, <span
class="math inline">\(p(\hat{x}_s(T+\tau))\)</span>.</li>
<li>Set the final predictions by calculating the expectation of the
above density function <span
class="math inline">\(\mathbb{E}_{p}(\hat{x}_s(T+\tau))\)</span>.</li>
</ol>
<h4
id="using-false-nearest-neighbor-criterion-to-determine-embedding-dimension">Using
false nearest neighbor criterion to determine embedding dimension</h4>
<p>The purpose to choose a large enough <span
class="math inline">\(E\)</span> is to eliminate all self-crossings of
the attractor. <span class="math inline">\(E&gt;2d\)</span> is obviously
sufficient, but often we don't know the exact value of <span
class="math inline">\(d\)</span> and <span
class="math inline">\(E\leqslant 2d\)</span> is enough. The false
nearest neighbor criterion (FNN) was proposed by Kennel, Brown and
Abarbanel<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="M. B. Kennel, R. Brown, and H. D. I. Abarbanel, “Determining embedding dimension for phase-space reconstruction using a geometrical construction,” Phys. Rev. A, vol. 45, no. 6, pp. 3403–3411, Mar. 1992, doi: 10.1103/PhysRevA.45.3403.">[3]</span></a></sup>
to determine <span class="math inline">\(E\)</span> in a model-free
way.</p>
<p>Denote <span
class="math inline">\(\bm{x}_s(t,E)=(x_s(t),x_s(t+\tau),\cdots
,x_s(t+(E-1)\tau))\)</span>. For a fix <span
class="math inline">\(t\)</span>, let <span
class="math inline">\(\bm{x}_s(t^{(r)},E)\)</span> be the <span
class="math inline">\(r\)</span>th nearest neighbor of <span
class="math inline">\(\bm{x}_s(t,E)\)</span>. The square of the
Euclidian distance between <span
class="math inline">\(\bm{x}_s(t,E)\)</span> and <span
class="math inline">\(\bm{x}_s(t^{(r)},E)\)</span> is</p>
<p><span class="math display">\[
    R_{E}^{2}(t,r)=\sum_{k=0}^{E-1}
[x_s(t+k\tau)-x_s(t^{(r)}+k\tau)]^{2}
\]</span></p>
<p>The idea is if <span
class="math inline">\(\bm{x}_s(t^{(r)},E)\)</span> is a false nearest
neighbor, meaning it's a self-crossing due to projection, then <span
class="math inline">\(R_{E+1}^{2}(t,r)-R_{E}^{2}(t,r)\)</span> is large
when <span class="math inline">\(E\)</span> passed the critical value.
It is defined as a false nearest neighbor if <span
class="math display">\[
    \left( \frac{R_{E+1}^{2}(t,r)-R_{E}^{2}(t,r)}{R_{E}^{2}(t,r)}
\right)^{\frac{1}{2}}=\frac{\lvert x_s(t+E\tau)-x_s(t^{(r)}+E\tau)
\rvert }{R_{E}(t,r)} &gt; R_{tol}
\]</span></p>
<p>Another situation is the limited data set size. The authors used
another criterion to avoid false nearest neighbors that are not close in
the original attractor. <span class="math display">\[
    \frac{R_{E+1}(t)}{R_{A}}&gt;A_{tol}
\]</span></p>
<p><span class="math inline">\(R_{A}\)</span> is a measure of the size
of the attractor <span class="math display">\[
    R_{A}^{2}=\frac{1}{N}\sum_{n=1}^{N} [x_s(t_n)-\bar{x}_s]^{2} \\
    \bar{x}_s=\frac{1}{N}\sum_{n=1}^{N} x_s(t_n)
\]</span></p>
<p>where <span class="math inline">\(t_n\)</span> are all time points of
the time series. <span class="math inline">\(E\)</span> is chosen so
that there is no false nearest neighbor.</p>
<h4
id="using-kernel-density-estimation-to-estimate-the-probability-density-function">Using
kernel density estimation to estimate the probability density
function</h4>
<p>The underlying probability density function is estimated as <span
class="math display">\[
    \hat{f}(x)=\sum_{i}^{} \alpha_i K(x-x_i)
\]</span></p>
<p>where <span class="math inline">\(K\)</span> is a kernel, typically a
Gaussian, centered at the data points, <span class="math inline">\(x_i,
i=1,\cdots ,n\)</span>, and <span
class="math inline">\(\alpha_i\)</span> are weighting coefficients,
typically uniform <span
class="math inline">\(\alpha=\frac{1}{n}\)</span>. A good discussion of
kernel estimation techniques can be
found<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span
class="hint--top hint--rounded"
aria-label="D. W. Scott, Multivariate Density Estimation: Theory, Practice, and Visualization, 1st ed. in Wiley Series in Probability and Statistics. Wiley, 1992. doi: 10.1002/9780470316849.">[7]</span></a></sup>.</p>
<h3 id="change-point-detection">Change-point detection</h3>
<p>TBC.</p>
<h2 id="reference">Reference</h2>
<section class="footnotes">
<div class="footnote-list">
<ol>
<li>
<span id="fn:1" class="footnote-text"><span>J.-W. Hou, H.-F. Ma, D. He,
J. Sun, Q. Nie, and W. Lin, “Harvesting random embedding for
high-frequency change-point detection in temporal complex systems,”
National Science Review, vol. 9, no. 4, p. nwab228, May 2022, doi:
10.1093/nsr/nwab228.
<a href="#fnref:1" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:2" class="footnote-text"><span>J. P. Huke, “Embedding
Nonlinear Dynamical Systems: A Guide to Takens’ Theorem.” Mar. 2006.
[Online]. Available: https://api.semanticscholar.org/CorpusID:55183186
<a href="#fnref:2" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:3" class="footnote-text"><span>M. B. Kennel, R. Brown, and
H. D. I. Abarbanel, “Determining embedding dimension for phase-space
reconstruction using a geometrical construction,” Phys. Rev. A, vol. 45,
no. 6, pp. 3403–3411, Mar. 1992, doi: 10.1103/PhysRevA.45.3403.
<a href="#fnref:3" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:4" class="footnote-text"><span>H. Ma, S. Leng, K. Aihara,
W. Lin, and L. Chen, “Randomly distributed embedding making short-term
high-dimensional data predictable,” Proc. Natl. Acad. Sci. U.S.A., vol.
115, no. 43, Oct. 2018, doi: 10.1073/pnas.1802987115.
<a href="#fnref:4" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:5" class="footnote-text"><span>J. Penalva Vadell, “Takens’s
theorem proof and applications.pdf.” 2018.
<a href="#fnref:5" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:6" class="footnote-text"><span>T. Sauer, J. A. Yorke, and
M. Casdagli, “Embedology,” J Stat Phys, vol. 65, no. 3–4, pp. 579–616,
Nov. 1991, doi: 10.1007/BF01053745.
<a href="#fnref:6" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:7" class="footnote-text"><span>D. W. Scott, Multivariate
Density Estimation: Theory, Practice, and Visualization, 1st ed. in
Wiley Series in Probability and Statistics. Wiley, 1992. doi:
10.1002/9780470316849.
<a href="#fnref:7" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
<li>
<span id="fn:8" class="footnote-text"><span>F. Takens, “Detecting
strange attractors in turbulence,” in Dynamical Systems and Turbulence,
Warwick 1980, vol. 898, D. Rand and L.-S. Young, Eds., in Lecture Notes
in Mathematics, vol. 898. , Berlin, Heidelberg: Springer Berlin
Heidelberg, 1981, pp. 366–381. doi: 10.1007/BFb0091924.
<a href="#fnref:8" rev="footnote" class="footnote-backref">
↩︎</a></span></span>
</li>
</ol>
</div>
</section>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/dynamical-system/" class="category-chain-item">dynamical system</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/math/" class="print-no-link">#math</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Takens&#39;s Theorem</div>
      <div>http://example.com/2023/10/04/Takens-s-Theorem/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>October 4, 2023</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/10/18/Network-Effects-in-Neurostimulation-2/" title="Network Effects in Neurostimulation (2)">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Network Effects in Neurostimulation (2)</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/09/30/Network-Effects-in-Neurostimulation-1/" title="Network Effects in Neurostimulation (1)">
                        <span class="hidden-mobile">Network Effects in Neurostimulation (1)</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
